{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy as tp\n",
    "import requests\n",
    "import yaml\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm as log_progress\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('data_files/twitter-archive-enhanced.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_file_url = \"https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv\"\n",
    "r = requests.get(predictions_file_url)\n",
    "with open('data_files/image-predictions.tsv', 'wb') as f:\n",
    "        f.write(r.content)\n",
    "predictions = pd.read_csv('data_files/image-predictions.tsv','\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = yaml.load(open('parameters.yml'), Loader=yaml.BaseLoader)['parameters']\n",
    "auth = tp.OAuthHandler(parameters['key'], parameters['key_secret'])\n",
    "auth.set_access_token(parameters['token'], parameters['token_secret'])\n",
    "api = tp.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipped_tweets = []\n",
    "\n",
    "with open('data_files/tweet_json.txt', 'w') as data_file, open ('data_files/tweet_json_failed.txt', 'w') as failed_data_file:\n",
    "    for tweet_id in log_progress(tweets['tweet_id']):\n",
    "        try:\n",
    "            while True:\n",
    "                try:\n",
    "                    result = api.get_status(tweet_id)\n",
    "                    break\n",
    "                except tp.RateLimitError:\n",
    "                    time.sleep(60)\n",
    "            data_file.write(json.dumps(result._json))\n",
    "            data_file.write('\\n')\n",
    "        except tp.TweepError as e:\n",
    "            record = {'tweet_id':tweet_id, 'error':e.response.text}\n",
    "            skipped_tweets.append(record)\n",
    "            failed_data_file.write(json.dumps(record))\n",
    "            failed_data_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_data = []\n",
    "with open('data_files/tweet_json.txt', 'r') as data_file:\n",
    "    line = data_file.readline()\n",
    "    while line:\n",
    "        line = json.loads(line) \n",
    "        api_data.append({'tweet_id':line['id'], 'retweets': line['retweet_count'], 'likes': line['favorite_count']})\n",
    "        line = data_file.readline()\n",
    "\n",
    "        \n",
    "reactions = pd.DataFrame(api_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.name.str.len() < 3].name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.rating_denominator.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(tweets.timestamp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.tweet_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.name.str.lower() == tweets.name].name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in tweets[tweets.rating_denominator != 10].iterrows():\n",
    "    print('{} , {}\\n {} \\n'.format(tweets.loc[index, ['rating_numerator']], tweets.loc[index, ['rating_denominator']], tweets.loc[index, ['text']].iloc[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.p1_dog.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions.p1_dog == False].p2_dog.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[predictions.p1_dog == False][predictions.p2_dog == False].p3_dog.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.p1.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    skipped_tweets\n",
    "except NameError:\n",
    "    print('Skipped tweets is not defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    skipped_tweets[:5]\n",
    "except NameError:\n",
    "    print('Skipped tweets is not defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.tweet_id == 888202515573088257].text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.tweet_id == 775096608509886464].text.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.tweet_id == 775096608509886464]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[tweets.tweet_id == 771004394259247104].text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quality\n",
    "##### `tweets` \n",
    "- timestamp is a string\n",
    "- `name`, `pupper`, `doggo`, `puppo`, `floofer`,  column is set to 'None' when there is no value \n",
    "- `name` column has a lot of incorrect values like `a` (55 records), `by`, `very`, `an`, `the`... etc\n",
    "- `text` include urls which misleads the actual length of the tweet\n",
    "- Issues with the extracted denominator:\n",
    "    - a. wrongly extracted denominator, while a correct value does exist\n",
    "    - b. a denominator has a value of 0\n",
    "    - c. an incorrect value of 24/7 rating is extracted\n",
    "    - d. inconsistent values\n",
    "\n",
    "##### `reactions`\n",
    "- 25 tweets missing like and retweet count (**Can't fix**)\n",
    "- some records are retweets\n",
    "\n",
    "#### Tidiness\n",
    "- rating is represented in two columns\n",
    "- dog category is splitted in 4 columns\n",
    "- multiple predictions are available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make copies to preserve the original data\n",
    "tweets_clean = tweets.copy()\n",
    "predictions_clean = predictions.copy()\n",
    "reactions_clean = reactions.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Quality_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.`tweets` timestamp is a string\n",
    "#### Define\n",
    "- convert timestamp to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "tweets_clean.timestamp = pd.to_datetime(tweets_clean.timestamp)\n",
    "\n",
    "# extract month and year, would be useful later\n",
    "tweets_clean['month_year'] = tweets_clean.timestamp.apply(lambda x: str(x.month) + '/' + str(x.year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "print(type(tweets_clean.timestamp[0]))\n",
    "print(tweets_clean.month_year[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.`tweets` name,pupper,doggo,puppo and floofer columns is set to 'None' when there is no value \n",
    "\n",
    "#### Define\n",
    "- replace the string 'None' with Nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "tweets_clean.replace('None', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "assert len(tweets_clean[tweets_clean.name == 'None']) == 0\n",
    "assert len(tweets_clean[tweets_clean.pupper == 'None']) == 0\n",
    "tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.`tweets` 'name' column has incorrect values \n",
    "\n",
    "#### Define\n",
    "- replace the string 'a', 'an', 'by', etc with Nan (A useful note is that all caught invalid strings are in lower case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "values_to_remove = tweets_clean[tweets_clean.name.str.lower() == tweets.name].name.value_counts()\n",
    "tweets_clean.replace(values_to_remove.keys(), np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "tweets_clean[tweets_clean.name.str.lower() == tweets.name].name.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.`tweets` 'text' include urls which misleads the actual length of the tweet\n",
    "\n",
    "#### Define\n",
    "- remove urls from text if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "tweets_clean.text = tweets_clean.text.str.split('http', n =1, expand = True)[0]\n",
    "tweets_clean.text = tweets_clean.text.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "print('Before : {}, After: {}'.format(tweets.text.str.contains('http').sum(), tweets_clean.text.str.contains('http').sum()))\n",
    "tweets_clean.sample().text.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.`tweets` Issues with the extracted denominator:\n",
    "- a. wrongly extracted denominator, while a correct value does exist\n",
    "- b. a denominator has a value of 0\n",
    "\n",
    "#### Define\n",
    "- re-extract a valid rating from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "not_10_denom_records = tweets_clean[tweets_clean.rating_denominator != 10]\n",
    "rating_parts = not_10_denom_records.text.str.extract('([0-9]+)/10').dropna()\n",
    "rating_parts\n",
    "for index, row in rating_parts.iterrows():\n",
    "    tweets_clean.rating_numerator[index] = row[0]\n",
    "    tweets_clean.rating_denominator[index] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test \n",
    "\n",
    "\n",
    "assert len(tweets_clean[tweets_clean.rating_denominator == 0]) == 0\n",
    "assert len(tweets[tweets.rating_denominator == 10]) < len(tweets_clean[tweets_clean.rating_denominator == 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.`tweets` Issues with the extracted denominator:\n",
    "- c. an incorrect value of 24/7 rating is extracted\n",
    "\n",
    "#### Define\n",
    "- drop the rating for this tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "index_to_clean = tweets_clean[tweets_clean.rating_numerator == 24][tweets_clean.rating_denominator == 7].index\n",
    "for i in index_to_clean:\n",
    "    tweets_clean.rating_numerator[i] = np.nan\n",
    "    tweets_clean.rating_denominator[i] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "assert len(tweets_clean[tweets_clean.rating_numerator == 24][tweets_clean.rating_denominator == 7]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.`tweets` Issues with the extracted denominator:\n",
    "- d. rating denominators are not consistent\n",
    "\n",
    "#### Define\n",
    "- convert denominators to 100 and adjust the numenator accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "tweets_clean.rating_numerator = tweets_clean.rating_numerator*100.0/ tweets_clean.rating_denominator\n",
    "tweets_clean.rating_denominator = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "sample = tweets_clean.sample(10)\n",
    "for index, row in sample.iterrows():\n",
    "    assert int(row.rating_numerator/row.rating_denominator) == int(tweets.rating_numerator[index]/tweets.rating_denominator[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Tidiness_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.`breeds are presented in multiple columns`\n",
    "#### Define\n",
    "- create two new columns containing the first dog breed availble and its conf or NaN if all predictions are not breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "predictions_clean['breed'] = predictions_clean[predictions_clean.p1_dog].p1\n",
    "predictions_clean['conf'] = predictions_clean[predictions_clean.p1_dog].p1_conf\n",
    "\n",
    "for index, row in predictions_clean.iterrows():\n",
    "    if pd.isna(row.breed):\n",
    "        if row.p2_dog:\n",
    "            predictions_clean.iloc[index, 12] = row.p2\n",
    "            predictions_clean.iloc[index, 13] = row.p2_conf\n",
    "        elif row.p3_dog:\n",
    "            predictions_clean.iloc[index, 12] = row.p3\n",
    "            predictions_clean.iloc[index, 13] = row.p3_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "test_sample = predictions_clean.sample(10)\n",
    "for index, row in test_sample.iterrows():\n",
    "    print('({}, {}, {}) => \\n {}\\n'.format(row.p1, row.p2, row.p3 ,row.breed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.`rating is represented in two columns, the denominator is redundant`\n",
    "#### Define\n",
    "- drop the denominator and rename the numenator to rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "tweets_clean.drop(columns=['rating_denominator'], inplace=True)\n",
    "tweets_clean.rename(columns={'rating_numerator': 'rating'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "tweets_clean.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.`dog category is splitted in 4 columns`\n",
    "\n",
    "#### Define\n",
    "- Create a new column that has the type of the dog\n",
    "- Drop category columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "temp = tweets_clean.copy()\n",
    "temp['index'] = temp.index.copy()\n",
    "temp = temp.melt(id_vars=['index'], value_vars=['doggo', 'floofer', 'pupper', 'puppo']).dropna()\n",
    "temp = temp.sort_values('index')\n",
    "temp.set_index(temp['index'],inplace=True)\n",
    "tweets_clean.loc[temp.index,'type']= temp['value']\n",
    "tweets_clean.drop(columns=['doggo', 'floofer', 'pupper', 'puppo'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1\n",
    "\n",
    "tweets_clean.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2\n",
    "\n",
    "tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.data is splitted in mutliple tables\n",
    "\n",
    "#### Define\n",
    "- merge `predictions`, `reactions` tables into `tweets` using the tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code\n",
    "\n",
    "tweets_clean = tweets_clean.merge(predictions_clean.loc[:, ['tweet_id','breed', 'conf']], on =['tweet_id'], how ='left')\n",
    "tweets_clean = tweets_clean.merge(reactions_clean, on =['tweet_id'], how ='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "tweets_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### _Quality_\n",
    "8.`tweets`, `reactions` some records are retweets\n",
    "\n",
    "#### Define\n",
    "- fetch original tweet id for retweets and filter by WeRateDog account\n",
    "- update like and retweet count based on the tweet_id\n",
    "- update tweet_id value\n",
    "- drop reactions for the rest of the retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "# Removed because none of the retweets ids were actually found\n",
    "\n",
    "# original_tweet_ids = tweets_clean[~tweets_clean.retweeted_status_id.isna()].copy()\n",
    "# original_tweet_ids.retweeted_status_id.iloc[0]\n",
    "#for tweet_id in log_progress(original_tweet_ids.retweeted_status_id):\n",
    "#     try:\n",
    "#         while True:\n",
    "#             try:\n",
    "#                 result = api.get_status(tweet_id)\n",
    "#                 break\n",
    "#             except tp.RateLimitError:\n",
    "#                 time.sleep(60)\n",
    "#     except tp.TweepError as e:\n",
    "#         print(e)\n",
    "#         continue\n",
    "#     # override\n",
    "#     record = original_tweet_ids[original_tweet_ids.retweeted_status_id == tweet_id]\n",
    "#     record.tweet_id = tweet_id\n",
    "#     record.retweets = result._json['retweet_count'] \n",
    "#     record.likes = result._json['favorite_count']\n",
    "\n",
    "index = tweets_clean[~tweets_clean.retweeted_status_id.isna()].index\n",
    "tweets_clean.loc[index, 'retweets'] = np.nan\n",
    "tweets_clean.loc[index, 'likes'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test \n",
    "\n",
    "assert len(tweets_clean[~tweets_clean.retweeted_status_id.isna()][~tweets_clean.retweets.isna()]) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. breed column contain multiple formats\n",
    "\n",
    "#### Define\n",
    "- replace `_` with space\n",
    "- capitalize the first letter in all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code \n",
    "\n",
    "tweets_clean.breed = tweets_clean.breed.str.replace('_', ' ').str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "\n",
    "tweets_clean.breed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store cleaned data\n",
    "tweets_clean.to_csv('data_files/twitter_archive_master.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid black\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**which dog breeds tend to get better ratings?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean = pd.read_csv('data_files/twitter_archive_master.csv')\n",
    "tweets_clean.groupby('breed').mean().rating.plot(kind ='pie', labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**which dog breeds are more popular?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.groupby('breed').mean().likes.plot(kind ='pie', labels=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.groupby('breed').mean().retweets.plot(kind ='pie', labels=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Taking a closer look**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.groupby('breed').mean().retweets.nlargest(5).plot(kind ='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.groupby('breed').mean().likes.nlargest(5).plot(kind ='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.groupby('breed').mean().rating.nlargest(5).plot(kind ='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**which dog types get more ratings?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.groupby('type').mean().rating.plot(kind ='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**which dog types are more popular?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.groupby('type').mean().loc[:, ['likes', 'retweets']].plot(kind ='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**how popular are the account tweets based on the given data sample?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean.sort_values('timestamp').groupby('month_year', sort =False).mean().loc[:, ['likes', 'retweets']].plot(kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does the tweet length affect the tweet popularity?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outliers in a simple way\n",
    "tweets_clean['tweet_len'] = tweets_clean.text.str.len()\n",
    "tweets_clean[tweets_clean.retweets < 20000].plot.scatter('tweet_len', 'retweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_clean[tweets_clean.likes < 20000].plot.scatter('tweet_len', 'likes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
